/**
 * è¯­éŸ³åŠŸèƒ½è·¯ç”± - é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«å’ŒåˆæˆæœåŠ¡
 * æ”¯æŒå³æ—¶è¯­éŸ³èŠå¤©åŠŸèƒ½
 */
const express = require('express')
const axios = require('axios')
const multer = require('multer')
const fs = require('fs')
const path = require('path')
const { spawn } = require('child_process')
const FormData = require('form-data')
const router = express.Router()
const WebSocket = require('ws')
const { v4: uuidv4 } = require('uuid')

// é…ç½®æ–‡ä»¶ä¸Šä¼ 
const upload = multer({ 
  dest: 'uploads/audio/',
  limits: {
    fileSize: 10 * 1024 * 1024 // 10MBé™åˆ¶
  }
})

// ğŸ“‹ æ ¹æ®é˜¿é‡Œäº‘å®˜æ–¹æ–‡æ¡£é…ç½®è¯­éŸ³æœåŠ¡
const SPEECH_CONFIG = {
  // è¯­éŸ³åˆæˆé…ç½® - ä½¿ç”¨æ­£ç¡®çš„DashScope APIæ ¼å¼
  tts: {
    apiKey: process.env.QWEN_API_KEY || process.env.DASHSCOPE_API_KEY || 'sk-a791758fe21c4a719b2c632d5345996f',
    baseUrl: 'https://dashscope.aliyuncs.com/api/v1/services/audio/tts',  // ğŸ”§ ä½¿ç”¨æ­£ç¡®çš„APIç«¯ç‚¹
    model: 'cosyvoice-v1',  
    timeout: 30000,
    
    // å®˜æ–¹éŸ³è‰²é…ç½®
    voices: {
      'longxiaobai': { name: 'é¾™å°ç™½', description: 'èŠå¤©æ•°å­—äººã€æœ‰å£°ä¹¦ã€è¯­éŸ³åŠ©æ‰‹' },
      'longxiaochun': { name: 'é¾™å°æ·³', description: 'è¯­éŸ³åŠ©æ‰‹ã€å¯¼èˆªæ’­æŠ¥ã€èŠå¤©æ•°å­—äºº' },
      'longxiaocheng': { name: 'é¾™å°è¯š', description: 'è¯­éŸ³åŠ©æ‰‹ã€å¯¼èˆªæ’­æŠ¥ã€èŠå¤©æ•°å­—äºº' },
      'longxiaoxia': { name: 'é¾™å°å¤', description: 'è¯­éŸ³åŠ©æ‰‹ã€èŠå¤©æ•°å­—äºº' },
      'longwan': { name: 'é¾™å©‰', description: 'è¯­éŸ³åŠ©æ‰‹ã€å¯¼èˆªæ’­æŠ¥ã€èŠå¤©æ•°å­—äºº' },
      'longcheng': { name: 'é¾™æ©™', description: 'è¯­éŸ³åŠ©æ‰‹ã€å¯¼èˆªæ’­æŠ¥ã€èŠå¤©æ•°å­—äºº' },
      'longhua': { name: 'é¾™å', description: 'è¯­éŸ³åŠ©æ‰‹ã€å¯¼èˆªæ’­æŠ¥ã€èŠå¤©æ•°å­—äºº' },
      'xiaoyun': { name: 'å°äº‘', description: 'é€šç”¨å¥³å£°', fallback: 'longxiaobai' },
      'xiaogang': { name: 'å°åˆš', description: 'é€šç”¨ç”·å£°', fallback: 'longxiaocheng' }
    }
  },
  
  // è¯­éŸ³è¯†åˆ«é…ç½®
  asr: {
    apiKey: process.env.QWEN_API_KEY || process.env.DASHSCOPE_API_KEY || 'sk-a791758fe21c4a719b2c632d5345996f',
    baseUrl: 'https://dashscope.aliyuncs.com/api/v1/services/audio/asr',
    model: 'paraformer-realtime-v2',
    timeout: 30000
  }
}

/**
 * ğŸ¤ å³æ—¶è¯­éŸ³è¯†åˆ«æ¥å£
 * POST /api/speech/recognize
 */
router.post('/recognize', upload.single('audio'), async (req, res) => {
  const startTime = Date.now()
  
  try {
    console.log('ğŸ¤ æ”¶åˆ°å³æ—¶è¯­éŸ³è¯†åˆ«è¯·æ±‚')
    
    let audioFile = null
    let audioData = null
    
    // å¤„ç†ä¸åŒçš„éŸ³é¢‘è¾“å…¥æ ¼å¼
    if (req.file) {
      // æ–‡ä»¶ä¸Šä¼ å½¢å¼
      audioFile = req.file.path
      console.log('ğŸ“ éŸ³é¢‘æ–‡ä»¶è·¯å¾„:', audioFile)
    } else if (req.body.audioData) {
      // Base64éŸ³é¢‘æ•°æ®
      audioData = req.body.audioData
      console.log('ğŸ“ Base64éŸ³é¢‘æ•°æ®é•¿åº¦:', audioData.length)
    } else {
      console.warn('âš ï¸ è¯­éŸ³è¯†åˆ«æš‚æœªå®ç°ï¼Œè¿”å›æ¨¡æ‹Ÿç»“æœ')
      return getMockRecognitionResult(res, startTime)
    }

    // æ£€æŸ¥APIå¯†é’¥é…ç½®
    if (!SPEECH_CONFIG.asr.apiKey) {
      console.warn('âš ï¸ è¯­éŸ³è¯†åˆ«APIå¯†é’¥æœªé…ç½®ï¼Œè¿”å›æ¨¡æ‹Ÿç»“æœ')
      return getMockRecognitionResult(res, startTime)
    }

    let recognitionResult
    
    try {
      // ğŸ”§ ä»è¯·æ±‚ä¸­è·å–éŸ³é¢‘æ ¼å¼ï¼Œé»˜è®¤ä¸ºMP3
      const audioFormat = req.body.format || 'mp3'
      console.log('ğŸµ ä½¿ç”¨éŸ³é¢‘æ ¼å¼:', audioFormat)
      
      // è°ƒç”¨é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«API
      recognitionResult = await callAliCloudASR(audioFile, audioData, audioFormat)
      
    } catch (apiError) {
      console.log('âŒ é˜¿é‡Œäº‘ASRè°ƒç”¨å¤±è´¥:', apiError.message)
      
      // ğŸ”§ æ£€æŸ¥æ˜¯å¦æ˜¯éŸ³é¢‘å¤§å°é—®é¢˜
      if (apiError.message.includes('éŸ³é¢‘æ•°æ®è¿‡å°')) {
        console.log('âš ï¸ éŸ³é¢‘æ•°æ®å¤ªå°ï¼Œè¿”å›æŒ‡å¯¼ä¿¡æ¯')
        
        const responseTime = Date.now() - startTime
        return res.json({
          success: false,
          message: 'éŸ³é¢‘å½•åˆ¶æ—¶é—´å¤ªçŸ­',
          detail: apiError.message,
          suggestion: 'è¯·é‡æ–°å½•åˆ¶ï¼Œç¡®ä¿è¯´è¯æ—¶é—´è‡³å°‘2-3ç§’ï¼ŒéŸ³è´¨æ¸…æ™°',
          responseTime,
          provider: 'error',
          errorType: 'AUDIO_TOO_SHORT'
        })
      }
      
      // ğŸ”§ å¯¹äºå…¶ä»–APIé”™è¯¯ï¼Œä¹Ÿæä¾›æ›´å¥½çš„é”™è¯¯ä¿¡æ¯
      if (apiError.message.includes('400') || apiError.message.includes('401') || apiError.message.includes('403')) {
        console.log('âš ï¸ APIé…ç½®é”™è¯¯ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯')
        
        const responseTime = Date.now() - startTime
        return res.json({
          success: false,
          message: 'è¯­éŸ³è¯†åˆ«æœåŠ¡æš‚æ—¶ä¸å¯ç”¨',
          detail: 'APIé…ç½®é”™è¯¯ï¼Œè¯·æ£€æŸ¥æœåŠ¡é…ç½®',
          responseTime,
          provider: 'error',
          errorType: 'API_CONFIG_ERROR'
        })
      }
      
      // ğŸ­ åªæœ‰åœ¨å…¶ä»–æƒ…å†µä¸‹æ‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
      console.log('ğŸ­ é™çº§ä½¿ç”¨æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«')
      return getMockRecognitionResult(res, startTime)
    }
    
    const responseTime = Date.now() - startTime
    console.log(`âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸ: "${recognitionResult}" (${responseTime}ms)`)
    
    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if (audioFile && fs.existsSync(audioFile)) {
      fs.unlinkSync(audioFile)
    }
    
    res.json({
      success: true,
      data: {
        text: recognitionResult,
        confidence: 0.95,
        responseTime,
        provider: 'alibaba-cloud'
      }
    })

  } catch (error) {
    console.error('âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥:', error)
    
    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if (req.file && fs.existsSync(req.file.path)) {
      fs.unlinkSync(req.file.path)
    }
    
    res.status(500).json({
      success: false,
      message: 'è¯­éŸ³è¯†åˆ«å¤±è´¥',
      error: process.env.NODE_ENV === 'development' ? error.message : undefined
    })
  }
})

/**
 * ğŸ¯ è°ƒç”¨DashScope Python SDKè¿›è¡Œè¯­éŸ³åˆæˆ
 * ä½¿ç”¨å­è¿›ç¨‹è°ƒç”¨Pythonè„šæœ¬ï¼Œç¡®ä¿APIè°ƒç”¨æ­£ç¡®
 */
async function callDashScopeTTS(text, voice, speed, pitch) {
  console.log('ğŸš€ ä½¿ç”¨DashScope Python SDKåˆæˆè¯­éŸ³...')
  
  return new Promise((resolve, reject) => {
    // åˆ›å»ºPythonè„šæœ¬å†…å®¹
    const pythonScript = `
import os
import sys
import json
import base64
import dashscope
from dashscope.audio.tts import SpeechSynthesizer

# è®¾ç½®API Key
dashscope.api_key = "${SPEECH_CONFIG.tts.apiKey}"

def synthesize_speech(text, voice, speed, pitch):
    try:
        # éŸ³è‰²æ˜ å°„å¤„ç† - ä¸WebSocketä¿æŒä¸€è‡´
        voice_map = {
            'xiaoyun': 'longxiaobai',
            'xiaogang': 'longxiaocheng'
        }
        mapped_voice = voice_map.get(voice, voice)
        
        # æ–‡æœ¬é¢„å¤„ç† - ç§»é™¤emojiå’Œç‰¹æ®Šå­—ç¬¦
        import re
        # ç§»é™¤emoji
        text = re.sub(r'[\U0001F600-\U0001F6FF\U0001F700-\U0001F77F\U0001F780-\U0001F7FF\U0001F800-\U0001F8FF\U00002600-\U000026FF\U00002700-\U000027BF]', '', text)
        # ç§»é™¤å…¶ä»–ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—å’ŒåŸºæœ¬æ ‡ç‚¹
        text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\sï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰,.!?;:()\-]', '', text)
        # æ¸…ç†å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text).strip()
        
        # è°ƒç”¨DashScopeè¯­éŸ³åˆæˆ
        response = SpeechSynthesizer.call(
            model='${SPEECH_CONFIG.tts.model}',
            text=text,
            voice=mapped_voice,
            format='mp3',
            sample_rate=22050,
            volume=50,
            speech_rate=speed or 1.0,
            pitch_rate=pitch or 1.0
        )
        
        if response.get_audio_data() is not None:
            # å°†éŸ³é¢‘æ•°æ®ç¼–ç ä¸ºbase64è¿”å›
            audio_base64 = base64.b64encode(response.get_audio_data()).decode('utf-8')
            result = {
                'success': True,
                'audioData': audio_base64,
                'provider': 'dashscope',
                'model': '${SPEECH_CONFIG.tts.model}',
                'voice': mapped_voice,
                'requestId': getattr(response, 'request_id', 'unknown')
            }
            print(json.dumps(result))
        else:
            error_msg = getattr(response, 'message', 'Unknown error')
            result = {
                'success': False,
                'error': f'No audio data received: {error_msg}',
                'provider': 'dashscope'
            }
            print(json.dumps(result))
            
    except Exception as e:
        result = {
            'success': False,
            'error': str(e),
            'provider': 'dashscope'
        }
        print(json.dumps(result))

if __name__ == "__main__":
    import sys
    args = json.loads(sys.argv[1])
    synthesize_speech(args['text'], args['voice'], args.get('speed'), args.get('pitch'))
`

    // å‡†å¤‡å‚æ•°
    const args = JSON.stringify({
      text: text,
      voice: voice,
      speed: speed,
      pitch: pitch
    })

    // å¯åŠ¨Pythonå­è¿›ç¨‹
    const pythonProcess = spawn('python3', ['-c', pythonScript, args], {
      stdio: ['pipe', 'pipe', 'pipe']
    })

    let stdout = ''
    let stderr = ''

    pythonProcess.stdout.on('data', (data) => {
      stdout += data.toString()
    })

    pythonProcess.stderr.on('data', (data) => {
      stderr += data.toString()
    })

    pythonProcess.on('close', (code) => {
      try {
        if (code === 0 && stdout.trim()) {
          const result = JSON.parse(stdout.trim())
          if (result.success) {
            console.log('âœ… DashScopeè¯­éŸ³åˆæˆæˆåŠŸ')
            console.log(`   æ¨¡å‹: ${result.model}`)
            console.log(`   éŸ³è‰²: ${result.voice}`)
            console.log(`   è¯·æ±‚ID: ${result.requestId}`)
            
            // è½¬æ¢base64ä¸ºBuffer
            const audioBuffer = Buffer.from(result.audioData, 'base64')
            resolve({
              audioData: audioBuffer,
              voice: result.voice,
              provider: 'dashscope',
              requestId: result.requestId
            })
          } else {
            console.error('âŒ DashScope APIè¿”å›é”™è¯¯:', result.error)
            reject(new Error(result.error))
          }
        } else {
          console.error('âŒ Pythonè¿›ç¨‹æ‰§è¡Œå¤±è´¥:')
          console.error('   é€€å‡ºç :', code)
          console.error('   æ ‡å‡†è¾“å‡º:', stdout)
          console.error('   é”™è¯¯è¾“å‡º:', stderr)
          reject(new Error(`Python process failed with code ${code}: ${stderr}`))
        }
      } catch (error) {
        console.error('âŒ è§£æPythonè¾“å‡ºå¤±è´¥:', error.message)
        console.error('   åŸå§‹è¾“å‡º:', stdout)
        reject(error)
      }
    })

    // è®¾ç½®è¶…æ—¶
    setTimeout(() => {
      pythonProcess.kill()
      reject(new Error('è¯­éŸ³åˆæˆè¶…æ—¶'))
    }, SPEECH_CONFIG.tts.timeout)
  })
}

/**
 * ğŸ­ æ¨¡æ‹Ÿè¯­éŸ³åˆæˆï¼ˆé™çº§æ–¹æ¡ˆï¼‰
 */
function generateMockAudio(text, voice, speed, pitch) {
  console.log('ğŸ­ ä½¿ç”¨æ¨¡æ‹Ÿè¯­éŸ³åˆæˆ')
  
  // ç”Ÿæˆæ¨¡æ‹Ÿçš„MP3éŸ³é¢‘æ•°æ® (ç®€å•çš„éŸ³é¢‘å¤´)
  const mp3Header = Buffer.from([
    0xFF, 0xFB, 0x90, 0x00, 0x00, 0x00, 0x00, 0x00,
    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
  ])
  
  // æ ¹æ®æ–‡æœ¬é•¿åº¦ç”Ÿæˆä¸åŒå¤§å°çš„æ•°æ®
  const textLength = text.length
  const audioSize = Math.max(1024, textLength * 100)
  const audioData = Buffer.alloc(audioSize)
  mp3Header.copy(audioData, 0)
  
  return {
    audioData: audioData,
    voice: voice,
    provider: 'mock',
    fallbackReason: 'DashScope API unavailable'
  }
}

/**
 * ğŸµ æ ¸å¿ƒè¯­éŸ³åˆæˆæœåŠ¡
 */
async function performSpeechSynthesis(text, voice = 'longxiaobai', speed = 1.0, pitch = 1.0) {
  console.log(`ğŸ¯ å¼€å§‹æ‰§è¡Œè¯­éŸ³åˆæˆï¼Œæ–‡æœ¬: ${text.substring(0, 50)}${text.length > 50 ? '...' : ''}`)
  console.log(`   éŸ³è‰²: ${voice}, è¯­é€Ÿ: ${speed}, éŸ³è°ƒ: ${pitch}`)

  // ğŸ”§ æ£€æŸ¥APIå¯†é’¥é…ç½®
  const hasValidApiKey = SPEECH_CONFIG.tts.apiKey && 
                        SPEECH_CONFIG.tts.apiKey.trim().length > 0 && 
                        !SPEECH_CONFIG.tts.apiKey.includes('your-api-key')
  
  if (!hasValidApiKey) {
    console.warn('âš ï¸ APIå¯†é’¥æœªé…ç½®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿè¯­éŸ³åˆæˆ')
    return generateMockAudio(text, voice, speed, pitch)
  }

  try {
    // ğŸš€ ä¼˜å…ˆä½¿ç”¨WebSocket APIè¿›è¡ŒçœŸå®è¯­éŸ³åˆæˆ
    console.log('ğŸ”— å°è¯•WebSocketè¯­éŸ³åˆæˆ...')
    console.log('ğŸ”‘ ä½¿ç”¨APIå¯†é’¥:', hasValidApiKey ? 'sk-a791758...' : 'æœªé…ç½®')
    
    const result = await callWebSocketTTSAPI(text, voice, speed, pitch)
    console.log('âœ… WebSocketè¯­éŸ³åˆæˆæˆåŠŸï¼ŒéŸ³é¢‘å¤§å°:', result.audioSize, 'å­—èŠ‚')
    
    return {
      audioData: result.audioData,
      audioUrl: result.audioUrl,
      duration: result.duration,
      originalText: result.originalText,
      processedText: result.processedText,
      audioSize: result.audioSize,
      qualityCheck: result.qualityCheck,
      voice: result.voice,
      provider: 'alibaba-cloud'
    }
    
  } catch (wsError) {
    console.error('âŒ WebSocketè¯­éŸ³åˆæˆå¤±è´¥:')
    console.error('   é”™è¯¯ç±»å‹:', wsError.name)
    console.error('   é”™è¯¯æ¶ˆæ¯:', wsError.message)
    console.error('   é”™è¯¯å †æ ˆ:', wsError.stack?.substring(0, 300))
    
    try {
      // ğŸ”§ é™çº§ä½¿ç”¨DashScope Python SDKï¼ˆå¦‚æœWebSocketå¤±è´¥ï¼‰
      console.log('ğŸ é™çº§ä½¿ç”¨Python SDK...')
      const result = await callDashScopeTTS(text, voice, speed, pitch)
      console.log('âœ… DashScope Python SDKè¯­éŸ³åˆæˆæˆåŠŸ')
      return result
      
    } catch (sdkError) {
      console.error('âŒ DashScope Python SDKè¯­éŸ³åˆæˆå¤±è´¥:')
      console.error('   é”™è¯¯ç±»å‹:', sdkError.name)  
      console.error('   é”™è¯¯æ¶ˆæ¯:', sdkError.message)
      console.log('ğŸ­ æœ€ç»ˆé™çº§ä½¿ç”¨æ¨¡æ‹Ÿè¯­éŸ³åˆæˆ')
      
      // æœ€åé™çº§ä½¿ç”¨æ¨¡æ‹Ÿæ–¹æ¡ˆ
      return generateMockAudio(text, voice, speed, pitch)
    }
  }
}

/**
 * ğŸµ è¯­éŸ³åˆæˆæ¥å£
 * POST /api/speech/synthesis
 */
router.post('/synthesis', async (req, res) => {
  const startTime = Date.now()
  
  try {
    console.log('ğŸ”Š æ”¶åˆ°å³æ—¶è¯­éŸ³åˆæˆè¯·æ±‚:', {
      text: req.body.text?.substring(0, 50) + (req.body.text?.length > 50 ? '...' : ''),
      voice: req.body.voice,
      speed: req.body.speed,
      pitch: req.body.pitch
    })

    const { text, voice = 'longxiaobai', speed = 1.0, pitch = 0 } = req.body

    // å‚æ•°éªŒè¯
    if (!text || text.trim().length === 0) {
      return res.status(400).json({
        success: false,
        error: 'æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º'
      })
    }

    if (text.length > 1000) {
      return res.status(400).json({
        success: false,
        error: 'æ–‡æœ¬é•¿åº¦ä¸èƒ½è¶…è¿‡1000å­—ç¬¦'
      })
    }

    // æ‰§è¡Œè¯­éŸ³åˆæˆ
    const result = await performSpeechSynthesis(text, voice, speed, pitch)
    
    const processingTime = Date.now() - startTime
    
    // ğŸ”§ æ£€æŸ¥æ˜¯å¦æ˜¯çœŸå®çš„éŸ³é¢‘æ•°æ®è¿˜æ˜¯æ¨¡æ‹Ÿæ•°æ®
    if (result.provider === 'mock' || !result.audioData || typeof result.audioData !== 'string') {
      console.log('ğŸ­ è¯­éŸ³åˆæˆé™çº§ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œè¿”å›JSONå“åº”')
      
      return res.json({
        success: true,
        data: {
          audioUrl: result.audioUrl,
          audioData: result.audioData,
          duration: result.duration || Math.ceil(text.length / 3),
          text: text,
          responseTime: processingTime,
          provider: result.provider || 'mock',
          voice: result.voice || voice,
          model: SPEECH_CONFIG.tts.model,
          processedText: result.processedText || text,
          audioSize: result.audioSize || 0,
          qualityCheck: result.qualityCheck || {
            size: 0,
            isValidSize: false,
            estimatedDuration: Math.ceil(text.length / 3),
            quality: 'mock',
            isValidMP3: false
          }
        }
      })
    }
    
    console.log(`âœ… çœŸå®è¯­éŸ³åˆæˆæˆåŠŸ (${processingTime}ms)`)
    
    // ğŸµ çœŸå®éŸ³é¢‘æ•°æ®ï¼šè¿”å›JSONæ ¼å¼ï¼ˆåŒ…å«base64éŸ³é¢‘ï¼‰
    return res.json({
      success: true,
      data: {
        audioUrl: `data:audio/mp3;base64,${result.audioData}`, // ğŸ”§ ç”Ÿæˆdata URL
        audioData: result.audioData, // ğŸ”§ ä¿æŒbase64æ ¼å¼ä¾›å‰ç«¯ä½¿ç”¨
        duration: result.duration || Math.ceil(text.length / 3),
        text: text,
        responseTime: processingTime,
        provider: result.provider,
        voice: result.voice,
        model: SPEECH_CONFIG.tts.model,
        processedText: result.processedText || text,
        audioSize: result.audioSize || 0,
        qualityCheck: result.qualityCheck || {
          size: result.audioSize || 0,
          isValidSize: result.audioSize >= 1000,
          estimatedDuration: Math.ceil(text.length / 3),
          quality: result.qualityCheck?.quality || 'real',
          isValidMP3: result.qualityCheck?.isValidMP3 || true
        }
      }
    })

  } catch (error) {
    const processingTime = Date.now() - startTime
    console.error('âŒ è¯­éŸ³åˆæˆæ¥å£é”™è¯¯:', error.message)
    
    res.status(500).json({
      success: false,
      error: 'è¯­éŸ³åˆæˆæœåŠ¡æš‚æ—¶ä¸å¯ç”¨',
      processingTime: processingTime + 'ms'
    })
  }
})

/**
 * ğŸ¯ å³æ—¶è¯­éŸ³èŠå¤©æ¥å£
 * POST /api/speech/instant-chat
 */
router.post('/instant-chat', upload.single('audio'), async (req, res) => {
  const startTime = Date.now()
  
  try {
    console.log('ğŸ¯ æ”¶åˆ°å³æ—¶è¯­éŸ³èŠå¤©è¯·æ±‚')
    
    // 1. è¯­éŸ³è¯†åˆ«
    const recognitionResult = await performSpeechRecognition(req)
    console.log('ğŸ¤ è¯†åˆ«ç»“æœ:', recognitionResult)
    
    // 2. AIå¤„ç†
    const { aiResponse } = await processAIChat(recognitionResult, req.body)
    console.log('ğŸ¤– AIå›å¤:', aiResponse.substring(0, 50) + '...')
    
    // 3. è¯­éŸ³åˆæˆ
    const synthesisResult = await performSpeechSynthesis(aiResponse, 'longxiaobai', 1.0, 0)
    console.log('ğŸ”Š åˆæˆå®Œæˆ')
    
    const responseTime = Date.now() - startTime
    console.log(`âœ… å³æ—¶è¯­éŸ³èŠå¤©å®Œæˆ (${responseTime}ms)`)
    
    res.json({
      success: true,
      data: {
        userInput: recognitionResult,
        aiResponse: aiResponse,
        audioUrl: synthesisResult.audioUrl || `data:audio/mp3;base64,${synthesisResult.audioData}`,
        audioData: synthesisResult.audioData,
        duration: synthesisResult.duration,
        responseTime,
        provider: synthesisResult.provider || 'unknown',
        components: {
          recognition: 'âœ…',
          aiProcessing: 'âœ…', 
          synthesis: 'âœ…'
        }
      }
    })

  } catch (error) {
    console.error('âŒ å³æ—¶è¯­éŸ³èŠå¤©å¤±è´¥:', error)
    
    res.status(500).json({
      success: false,
      message: 'å³æ—¶è¯­éŸ³èŠå¤©å¤±è´¥',
      error: process.env.NODE_ENV === 'development' ? error.message : undefined
    })
  }
})

/**
 * ğŸ“Š è·å–è¯­éŸ³åŠŸèƒ½çŠ¶æ€
 * GET /api/speech/status
 */
router.get('/status', async (req, res) => {
  try {
    const hasApiKey = SPEECH_CONFIG.tts.apiKey && 
                     SPEECH_CONFIG.tts.apiKey.trim().length > 0 && 
                     !SPEECH_CONFIG.tts.apiKey.includes('your-api-key')
    
    res.json({
      success: true,
      data: {
        speechSynthesis: {
          available: true,
          provider: hasApiKey ? 'alibaba-cloud' : 'mock',
          model: SPEECH_CONFIG.tts.model,
          supportedVoices: Object.entries(SPEECH_CONFIG.tts.voices).map(([id, info]) => ({
            id,
            name: info.name,
            description: info.description,
            language: 'ä¸­æ–‡',
            format: 'mp3'
          })),
          maxTextLength: 500
        },
        configured: hasApiKey,
        version: '3.0.0-dashscope-sdk',
        lastUpdate: '2025-01-27'
      }
    })
  } catch (error) {
    console.error('è·å–è¯­éŸ³çŠ¶æ€å¤±è´¥:', error)
    
    res.status(500).json({
      success: false,
      message: 'è·å–è¯­éŸ³çŠ¶æ€å¤±è´¥'
    })
  }
})

// ==================== è¾…åŠ©å‡½æ•° ====================

/**
 * ğŸ§  æ™ºèƒ½æ–‡æœ¬åˆ†æ®µå‡½æ•° - åœ¨è¯­ä¹‰è¾¹ç•Œå¤„åˆ†æ®µï¼Œä¿æŒæ•™å­¦é€»è¾‘å®Œæ•´
 * @param {string} text - åŸå§‹æ–‡æœ¬
 * @param {number} maxLength - æ¯æ®µæœ€å¤§é•¿åº¦
 * @returns {string} - åˆ†æ®µåçš„ç¬¬ä¸€æ®µæ–‡æœ¬ï¼ˆä¿æŒè¯­ä¹‰å®Œæ•´ï¼‰
 */
function intelligentTextSegment(text, maxLength = 50) {
  if (text.length <= maxLength) {
    return text
  }
  
  // ğŸ¯ è¯­ä¹‰è¾¹ç•Œä¼˜å…ˆçº§ï¼šå¥å· > é—®å· > æ„Ÿå¹å· > é€—å· > é¡¿å· > åˆ†å·
  const boundaries = [
    { char: 'ã€‚', priority: 1, isEnd: true },
    { char: 'ï¼Ÿ', priority: 2, isEnd: true },
    { char: 'ï¼', priority: 3, isEnd: true },
    { char: 'ï¼Œ', priority: 4, isEnd: false },
    { char: 'ã€', priority: 5, isEnd: false },
    { char: 'ï¼›', priority: 6, isEnd: false },
    { char: 'ï¼š', priority: 7, isEnd: false }
  ]
  
  let bestCutPoint = -1
  let bestPriority = 999
  let bestIsEnd = false
  
  // ğŸ” åœ¨æœ€å¤§é•¿åº¦èŒƒå›´å†…å¯»æ‰¾æœ€ä½³åˆ†æ®µç‚¹
  for (let i = Math.max(20, maxLength - 20); i < Math.min(text.length, maxLength + 10); i++) {
    const char = text[i]
    const boundary = boundaries.find(b => b.char === char)
    
    if (boundary) {
      // ä¼˜å…ˆé€‰æ‹©ä¼˜å…ˆçº§æ›´é«˜ï¼ˆæ•°å­—æ›´å°ï¼‰çš„è¾¹ç•Œ
      if (boundary.priority < bestPriority) {
        bestCutPoint = i + 1 // åŒ…å«æ ‡ç‚¹ç¬¦å·
        bestPriority = boundary.priority
        bestIsEnd = boundary.isEnd
      }
    }
  }
  
  // ğŸ¯ å¦‚æœæ‰¾åˆ°åˆé€‚çš„åˆ†æ®µç‚¹
  if (bestCutPoint > 0) {
    const segment = text.substring(0, bestCutPoint).trim()
    
    console.log('ğŸ§  æ™ºèƒ½åˆ†æ®µç»“æœ:', {
      originalLength: text.length,
      segmentLength: segment.length,
      cutPoint: bestCutPoint,
      priority: bestPriority,
      isEndBoundary: bestIsEnd,
      segment: segment.substring(0, 30) + (segment.length > 30 ? '...' : '')
    })
    
    return segment
  }
  
  // ğŸ”§ å¦‚æœæ²¡æ‰¾åˆ°åˆé€‚çš„åˆ†æ®µç‚¹ï¼Œå¯»æ‰¾ç©ºæ ¼åˆ†è¯
  for (let i = maxLength - 10; i >= 20; i--) {
    if (text[i] === ' ' || text[i] === 'ã€€') { // ç©ºæ ¼æˆ–å…¨è§’ç©ºæ ¼
      const segment = text.substring(0, i).trim()
      console.log('ğŸ”¤ æŒ‰ç©ºæ ¼åˆ†æ®µ:', segment)
      return segment
    }
  }
  
  // ğŸš¨ æœ€åçš„å…œåº•æ–¹æ¡ˆï¼šæ™ºèƒ½æˆªæ–­ï¼Œé¿å…åœ¨è¯è¯­ä¸­é—´æˆªæ–­
  const safeLength = Math.max(30, maxLength - 10)
  const segment = text.substring(0, safeLength)
  
  console.log('âš ï¸ å…œåº•åˆ†æ®µæ–¹æ¡ˆ:', {
    originalLength: text.length,
    segmentLength: segment.length,
    segment: segment
  })
  
  return segment
}

/**
 * ğŸ¤ è°ƒç”¨é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«API - ä½¿ç”¨DashScopeå®˜æ–¹æ ¼å¼
 * åŸºäºå®˜æ–¹æ–‡æ¡£çš„é€šä¹‰åƒé—®ASRæ¨¡å‹
 */
async function callAliCloudASR(audioFile, audioData, format = 'mp3') {
  console.log('ğŸš€ è°ƒç”¨é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«API...')
  console.log('ğŸµ éŸ³é¢‘æ ¼å¼:', format)
  console.log('ğŸ”‘ APIå¯†é’¥:', SPEECH_CONFIG.asr.apiKey ? SPEECH_CONFIG.asr.apiKey.substring(0, 8) + '***' : 'æœªé…ç½®')
  
  // ğŸ”§ ä½¿ç”¨DashScopeé€šä¹‰åƒé—®ASRæ ¼å¼ï¼ˆå®˜æ–¹æ–‡æ¡£æ¨èï¼‰
  const base64Audio = audioData || (audioFile ? fs.readFileSync(audioFile).toString('base64') : null)
  
  if (!base64Audio) {
    throw new Error('æœªæä¾›éŸ³é¢‘æ•°æ®')
  }
  
  // ğŸ”§ æ£€æŸ¥éŸ³é¢‘æ•°æ®å¤§å° - DashScopeéœ€è¦è¶³å¤Ÿå¤§çš„éŸ³é¢‘æ•°æ®
  const audioSizeBytes = Math.ceil(base64Audio.length * 3 / 4) // Base64 to bytes
  console.log('ğŸ“ éŸ³é¢‘æ•°æ®å¤§å°:', {
    base64Length: base64Audio.length,
    estimatedBytes: audioSizeBytes,
    minimumRequired: 1000 // è‡³å°‘éœ€è¦1KBçš„éŸ³é¢‘æ•°æ®
  })
  
  // ğŸš¨ å¦‚æœéŸ³é¢‘å¤ªå°ï¼ŒæŠ›å‡ºæ˜ç¡®é”™è¯¯è€Œéä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
  if (audioSizeBytes < 1000) {
    console.log('âš ï¸ éŸ³é¢‘æ•°æ®å¤ªå°ï¼Œæ— æ³•è¿›è¡Œè¯­éŸ³è¯†åˆ«')
    console.log('ğŸ’¡ å»ºè®®ï¼šè¯·ç¡®ä¿å½•éŸ³æ—¶é•¿è‡³å°‘1-2ç§’ï¼ŒéŸ³è´¨æ¸…æ™°')
    throw new Error(`éŸ³é¢‘æ•°æ®è¿‡å°(${audioSizeBytes}å­—èŠ‚)ï¼Œéœ€è¦è‡³å°‘1KBçš„éŸ³é¢‘æ•°æ®ã€‚è¯·å½•åˆ¶æ›´é•¿æ—¶é—´çš„éŸ³é¢‘ã€‚`)
  }
  
  const requestData = {
    model: 'qwen-audio-asr', // ä½¿ç”¨é€šä¹‰åƒé—®ASRæ¨¡å‹
    input: {
      messages: [
        {
          role: 'user',
          content: [
            {
              audio: `data:audio/${format};base64,${base64Audio}`
            }
          ]
        }
      ]
    }
  }
  
  console.log('ğŸ“¤ å‘é€è¯­éŸ³è¯†åˆ«è¯·æ±‚åˆ°: https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation')
  console.log('ğŸ“ è¯·æ±‚æ•°æ®:', {
    model: requestData.model,
    audioFormat: format,
    audioSizeKB: Math.round(audioSizeBytes / 1024 * 10) / 10
  })
  
  const response = await axios.post('https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation', requestData, {
    headers: {
      'Authorization': `Bearer ${SPEECH_CONFIG.asr.apiKey}`,
      'Content-Type': 'application/json'
    },
    timeout: SPEECH_CONFIG.asr.timeout
  })
  
  console.log('ğŸ“¥ è¯­éŸ³è¯†åˆ«å“åº”çŠ¶æ€:', response.status)
  
  // ğŸ”§ å¤„ç†é€šä¹‰åƒé—®ASRå“åº”æ ¼å¼
  if (response.data && response.data.output && response.data.output.choices && response.data.output.choices.length > 0) {
    const choice = response.data.output.choices[0]
    if (choice.message && choice.message.content && choice.message.content.length > 0) {
      const recognizedText = choice.message.content[0].text
      console.log('âœ… çœŸå®è¯­éŸ³è¯†åˆ«æˆåŠŸ:', recognizedText)
      console.log('ğŸ“Š Tokenä½¿ç”¨:', response.data.usage)
      return recognizedText
    }
  }
  
  console.error('âŒ è¯­éŸ³è¯†åˆ«è¿”å›æ ¼å¼å¼‚å¸¸:', JSON.stringify(response.data))
  throw new Error('è¯­éŸ³è¯†åˆ«è¿”å›æ ¼å¼å¼‚å¸¸: ' + JSON.stringify(response.data))
}

/**
 * ğŸš€ è°ƒç”¨é˜¿é‡Œäº‘WebSocketè¯­éŸ³åˆæˆAPI
 * ä¿®å¤éŸ³é¢‘æ ¼å¼é—®é¢˜ï¼Œç¡®ä¿è¿”å›æ ‡å‡†MP3
 */
async function callWebSocketTTSAPI(text, voice, speed, pitch) {
  console.log('ğŸš€ ä½¿ç”¨WebSocketè°ƒç”¨é˜¿é‡Œäº‘è¯­éŸ³åˆæˆ...')
  
  // ğŸ”§ éŸ³è‰²æ˜ å°„å¤„ç† - å°†ä¸æ”¯æŒçš„éŸ³è‰²æ˜ å°„åˆ°æ”¯æŒçš„éŸ³è‰²
  const voiceMapping = {
    'xiaoyun': 'longxiaobai',
    'xiaogang': 'longxiaocheng'
  }
  const mappedVoice = voiceMapping[voice] || voice
  
  if (voice !== mappedVoice) {
    console.log(`ğŸ­ éŸ³è‰²æ˜ å°„: ${voice} -> ${mappedVoice}`)
  }
  
  // ğŸ”§ æ–‡æœ¬é¢„å¤„ç† - ç§»é™¤emojiä½†ä¿ç•™æ•°å­¦è¿ç®—ç¬¦
  let processedText = text.trim()
  
  // ç§»é™¤emojiå’Œç‰¹æ®Šç¬¦å·
  processedText = processedText.replace(/[\u{1F600}-\u{1F6FF}\u{1F700}-\u{1F77F}\u{1F780}-\u{1F7FF}\u{1F800}-\u{1F8FF}\u{2600}-\u{26FF}\u{2700}-\u{27BF}]/gu, '')
  
  // ç§»é™¤å…¶ä»–ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€åŸºæœ¬æ ‡ç‚¹å’Œæ•°å­¦è¿ç®—ç¬¦
  processedText = processedText.replace(/[^\u4e00-\u9fa5a-zA-Z0-9\sï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰,.!?;:()\-+=Ã—Ã·]/g, '')
  
  // æ¸…ç†å¤šä½™ç©ºæ ¼
  processedText = processedText.replace(/\s+/g, ' ').trim()
  
  console.log('ğŸ“ æ–‡æœ¬é¢„å¤„ç†:', {
    original: text.substring(0, 50) + (text.length > 50 ? '...' : ''),
    processed: processedText.substring(0, 50) + (processedText.length > 50 ? '...' : ''),
    removedEmojis: text !== processedText
  })
  
  // ğŸ¯ æ™ºèƒ½æ–‡æœ¬é•¿åº¦æ§åˆ¶ - è¯­ä¹‰è¾¹ç•Œåˆ†æ®µ
  if (processedText.length < 2) {
    processedText = processedText + 'ï¼Œå¥½'
    console.log('ğŸ“ ç®€çŸ­æ‰©å……æ–‡æœ¬:', processedText)
  } else if (processedText.length > 50) {
    // ğŸ§  æ™ºèƒ½åˆ†æ®µï¼šåœ¨è¯­ä¹‰è¾¹ç•Œå¤„åˆ†æ®µï¼Œä¿æŒæ•™å­¦é€»è¾‘å®Œæ•´
    processedText = intelligentTextSegment(processedText, 50)
    console.log('ğŸ“ æ™ºèƒ½åˆ†æ®µæ–‡æœ¬:', processedText)
  }
  
  return new Promise((resolve, reject) => {
    const taskId = uuidv4()
    const wsUrl = `wss://dashscope.aliyuncs.com/api-ws/v1/inference/`
    
    console.log('ğŸ”— å»ºç«‹WebSocketè¿æ¥...')
    const ws = new WebSocket(wsUrl, {
      headers: {
        'Authorization': `Bearer ${SPEECH_CONFIG.tts.apiKey}`
      }
    })
    
    let audioBuffers = []
    let timeout
    let taskStarted = false
    let taskCompleted = false
    
    ws.on('open', () => {
      console.log('âœ… WebSocketè¿æ¥å·²å»ºç«‹')
      
      // ğŸ¯ ç¬¬ä¸€æ­¥ï¼šå‘é€run-taskæŒ‡ä»¤ï¼ˆä¸åŒ…å«æ–‡æœ¬ï¼‰
      const runTaskMessage = {
        header: {
          action: 'run-task',
          task_id: taskId,
          streaming: 'duplex'
        },
        payload: {
          task_group: 'audio',
          task: 'tts',
          function: 'SpeechSynthesizer',
          model: 'cosyvoice-v1',
          parameters: {
            text_type: 'PlainText',
            voice: mappedVoice,          // ğŸ”§ ä½¿ç”¨æ˜ å°„åçš„éŸ³è‰²
            format: 'mp3',              // ğŸ”§ ç¡®ä¿MP3æ ¼å¼
            sample_rate: 22050,         // ğŸ”§ ä½¿ç”¨æ ‡å‡†é‡‡æ ·ç‡
            volume: 50,                 // ğŸ”§ æ ‡å‡†éŸ³é‡
            rate: 1.0,                  // ğŸ”§ æ­£å¸¸è¯­é€Ÿç¡®ä¿è´¨é‡
            pitch: 1.0                  // ğŸ”§ æ ‡å‡†éŸ³è°ƒ
          },
          input: {}                     // ğŸ”§ run-taskä¸­ä¸å‘é€æ–‡æœ¬
        }
      }
      
      console.log('ğŸ“¤ ç¬¬ä¸€æ­¥ï¼šå‘é€run-taskæŒ‡ä»¤')
      console.log('ğŸ›ï¸ è¯­éŸ³é…ç½®:', {
        voice: runTaskMessage.payload.parameters.voice,
        format: runTaskMessage.payload.parameters.format,
        sample_rate: runTaskMessage.payload.parameters.sample_rate,
        volume: runTaskMessage.payload.parameters.volume,
        textLength: processedText.length
      })
      
      ws.send(JSON.stringify(runTaskMessage))
      
      // ğŸ”§ è®¾ç½®åˆç†è¶…æ—¶æ—¶é—´
      timeout = setTimeout(() => {
        console.log('â° WebSocketè¿æ¥è¶…æ—¶')
        if (!taskCompleted) {
          ws.close()
          reject(new Error('WebSocketè¿æ¥è¶…æ—¶'))
        }
      }, 45000)  // 45ç§’è¶…æ—¶ï¼Œç»™é˜¿é‡Œäº‘æ›´å¤šå¤„ç†æ—¶é—´
    })
    
    ws.on('message', (data) => {
      try {
        // ğŸ”§ å…ˆå°è¯•è§£æä¸ºJSONæ¶ˆæ¯
        const messageStr = data.toString()
        
        try {
          const message = JSON.parse(messageStr)
          console.log('ğŸ“¨ æ”¶åˆ°çŠ¶æ€æ¶ˆæ¯:', message.header?.event)
          
          if (message.header?.event === 'task-started') {
            console.log('âœ… ä»»åŠ¡å·²å¯åŠ¨ï¼Œå¼€å§‹å‘é€æ–‡æœ¬')
            taskStarted = true
            
            // ğŸ¯ ç¬¬äºŒæ­¥ï¼šå‘é€continue-taskæŒ‡ä»¤ï¼ˆåŒ…å«æ–‡æœ¬ï¼‰
            const continueTaskMessage = {
              header: {
                action: 'continue-task',
                task_id: taskId,
                streaming: 'duplex'
              },
              payload: {
                input: {
                  text: processedText
                }
              }
            }
            
            console.log('ğŸ“¤ ç¬¬äºŒæ­¥ï¼šå‘é€continue-taskæŒ‡ä»¤ï¼Œæ–‡æœ¬:', processedText)
            ws.send(JSON.stringify(continueTaskMessage))
            
            // ğŸ¯ ç¬¬ä¸‰æ­¥ï¼šç«‹å³å‘é€finish-taskæŒ‡ä»¤
            setTimeout(() => {
              const finishTaskMessage = {
                header: {
                  action: 'finish-task',
                  task_id: taskId,
                  streaming: 'duplex'
                },
                payload: {
                  input: {}
                }
              }
              
              console.log('ğŸ“¤ ç¬¬ä¸‰æ­¥ï¼šå‘é€finish-taskæŒ‡ä»¤')
              ws.send(JSON.stringify(finishTaskMessage))
            }, 100) // çŸ­æš‚å»¶è¿Ÿç¡®ä¿æ¶ˆæ¯é¡ºåº
          }
          
          // ğŸµ å¤„ç†éŸ³é¢‘æ•°æ®è¿”å› - DashScopeåœ¨payload.output.audioä¸­è¿”å›base64éŸ³é¢‘
          if (message.payload?.output?.audio) {
            console.log('ğŸµ æ”¶åˆ°base64éŸ³é¢‘æ•°æ®')
            const audioBase64 = message.payload.output.audio
            const audioBuffer = Buffer.from(audioBase64, 'base64')
            console.log('ğŸµ è½¬æ¢éŸ³é¢‘æ•°æ®:', audioBuffer.length, 'å­—èŠ‚')
            audioBuffers.push(audioBuffer)
          }
          
          if (message.header?.event === 'task-finished') {
            console.log('ğŸ‰ ä»»åŠ¡å®Œæˆ')
            taskCompleted = true
            // ğŸ”§ ç¨å¾®å»¶è¿Ÿå…³é—­ï¼Œç¡®ä¿æ¥æ”¶å®Œæ•´éŸ³é¢‘
            setTimeout(() => ws.close(), 100)
          }
          
          if (message.header?.event === 'task-failed') {
            console.error('âŒ ä»»åŠ¡å¤±è´¥:', message.header?.error_message || message.payload)
            taskCompleted = true
            ws.close()
            reject(new Error(`è¯­éŸ³åˆæˆå¤±è´¥: ${message.header?.error_message || 'æœªçŸ¥é”™è¯¯'}`))
          }
          
        } catch (parseError) {
          // ğŸµ å¦‚æœä¸æ˜¯JSONï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯çº¯äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
          if (data instanceof Buffer && data.length > 10) {
            // æ£€æŸ¥æ˜¯å¦æ˜¯MP3æ–‡ä»¶å¤´
            const header = data.slice(0, 3)
            if ((header[0] === 0xFF && (header[1] & 0xE0) === 0xE0) || data.toString('hex').startsWith('494433')) {
              console.log('ğŸµ æ¥æ”¶äºŒè¿›åˆ¶MP3éŸ³é¢‘ç‰‡æ®µ:', data.length, 'å­—èŠ‚')
              audioBuffers.push(data)
            } else {
              console.log('ğŸ“ æ”¶åˆ°ééŸ³é¢‘äºŒè¿›åˆ¶æ•°æ®:', data.length, 'å­—èŠ‚ï¼Œå¤´éƒ¨:', header.toString('hex'))
            }
          }
        }
      } catch (err) {
        console.warn('å¤„ç†æ¶ˆæ¯å¤±è´¥:', err.message)
      }
    })
    
    ws.on('close', () => {
      console.log('ğŸ”Œ WebSocketè¿æ¥å·²å…³é—­')
      if (timeout) clearTimeout(timeout)
      
      if (audioBuffers.length > 0) {
        const totalBuffer = Buffer.concat(audioBuffers)
        console.log('ğŸ‰ è¯­éŸ³åˆæˆå®Œæˆï¼Œæ€»éŸ³é¢‘é•¿åº¦:', totalBuffer.length, 'å­—èŠ‚')
        
        // ğŸ”§ éªŒè¯MP3æ ¼å¼
        let qualityCheck = {
          size: totalBuffer.length,
          isValidSize: totalBuffer.length >= 1000,  // MP3æ–‡ä»¶éœ€è¦è¶³å¤Ÿå¤§
          estimatedDuration: Math.ceil(processedText.length / 3),  // æ­£å¸¸è¯­é€Ÿæ—¶é•¿ä¼°ç®—
          quality: totalBuffer.length < 5000 ? 'compact' : 
                  totalBuffer.length < 20000 ? 'optimal' : 
                  totalBuffer.length < 50000 ? 'good' : 'large'
        }
        
        // ğŸ¯ æ£€æŸ¥MP3æ–‡ä»¶å¤´
        if (totalBuffer.length >= 3) {
          const header = totalBuffer.slice(0, 3)
          const headerHex = header.toString('hex')
          
          // MP3æ–‡ä»¶å¤´æ£€æŸ¥
          qualityCheck.isValidMP3 = 
            (header[0] === 0xFF && (header[1] & 0xE0) === 0xE0) ||  // æ ‡å‡†MP3å¤´
            headerHex.startsWith('494433') ||                        // ID3v2æ ‡ç­¾
            totalBuffer.length > 1000;                              // å¤§æ–‡ä»¶é€šå¸¸æ˜¯æœ‰æ•ˆçš„
          
          console.log('ğŸ” MP3æ ¼å¼åˆ†æ:', {
            headerHex: headerHex,
            isStandardMP3: (header[0] === 0xFF && (header[1] & 0xE0) === 0xE0),
            hasID3: headerHex.startsWith('494433'),
            size: totalBuffer.length,
            isValid: qualityCheck.isValidMP3
          })
        } else {
          qualityCheck.isValidMP3 = false
        }
        
        console.log('ğŸ” éŸ³é¢‘è´¨é‡æ£€æŸ¥:', qualityCheck)
        
        if (qualityCheck.isValidMP3 && qualityCheck.isValidSize) {
          console.log('âœ… MP3æ ¼å¼éªŒè¯é€šè¿‡ï¼Œå¯ä»¥æ’­æ”¾')
        } else {
          console.log('âš ï¸ MP3æ ¼å¼å¯èƒ½æœ‰é—®é¢˜ï¼Œä½†ä»å°è¯•æ’­æ”¾')
        }
        
        // è½¬æ¢ä¸ºBase64è¿”å›
        const audioData = totalBuffer.toString('base64')
        
        resolve({
          audioData: audioData,
          audioUrl: null,
          duration: qualityCheck.estimatedDuration,
          originalText: text,
          processedText: processedText,
          audioSize: totalBuffer.length,
          qualityCheck: qualityCheck,
          voice: mappedVoice // ğŸ”§ è¿”å›å®é™…ä½¿ç”¨çš„éŸ³è‰²
        })
      } else {
        console.error('âŒ æœªæ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®')
        reject(new Error('æœªæ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®'))
      }
    })
    
    ws.on('error', (error) => {
      console.error('âŒ WebSocketé”™è¯¯:', error)
      if (timeout) clearTimeout(timeout)
      reject(new Error(`WebSocketè¿æ¥å¤±è´¥: ${error.message}`))
    })
  })
}

// ğŸ—‘ï¸ å·²åˆ é™¤æ—§çš„HTTP APIè°ƒç”¨å‡½æ•° - ä½¿ç”¨WebSocketæ›¿ä»£

/**
 * æ‰§è¡Œè¯­éŸ³è¯†åˆ«
 */
async function performSpeechRecognition(req) {
  const audioFormat = req.body.format || 'mp3' // ğŸ”§ é»˜è®¤æ”¯æŒMP3æ ¼å¼
  
  if (req.file) {
    return await callAliCloudASR(req.file.path, null, audioFormat)
  } else if (req.body.audioData) {
    return await callAliCloudASR(null, req.body.audioData, audioFormat)
  } else {
    throw new Error('æœªæä¾›éŸ³é¢‘æ•°æ®')
  }
}

/**
 * å¤„ç†AIèŠå¤©
 */
async function processAIChat(userInput, requestBody) {
  // è¿™é‡Œè°ƒç”¨AIèŠå¤©æ¥å£
  const aiService = require('../services/aiService')
  
  const prompt = `å­¦ç”Ÿé€šè¿‡è¯­éŸ³è¯´ï¼š"${userInput}"
è¯·ä½ ä½œä¸ºAIè€å¸ˆï¼Œç”¨ç®€æ´å‹å¥½çš„è¯­è¨€å›å¤ï¼Œé€‚åˆå°å­¦ç”Ÿç†è§£ã€‚å›å¤è¦ï¼š
1. è¯­è¨€ç®€å•æ˜“æ‡‚
2. è¯­æ°”æ¸©å’Œé¼“åŠ±
3. æ§åˆ¶åœ¨50å­—ä»¥å†…
4. å¦‚æœæ˜¯æ•°å­¦é—®é¢˜ï¼Œç»™å‡ºå¼•å¯¼æ€§æç¤ºè€Œä¸æ˜¯ç›´æ¥ç­”æ¡ˆ

å­¦ç”Ÿçš„é—®é¢˜èƒŒæ™¯ï¼š${requestBody.question || 'ä¸€èˆ¬å­¦ä¹ é—®ç­”'}
å¹´çº§ï¼š${requestBody.grade || 'å°å­¦'}å¹´çº§
å­¦ç§‘ï¼š${requestBody.subject || 'æ•°å­¦'}`

  const aiResponse = await aiService.generateResponse(prompt, 'chat')
  
  return { aiResponse }
}

/**
 * è·å–æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«ç»“æœ
 */
function getMockRecognitionResult(res, startTime) {
  const mockResults = [
    'æˆ‘ä¸çŸ¥é“æ€ä¹ˆç®—',
    'è€å¸ˆèƒ½å¸®å¸®æˆ‘å—',
    'æˆ‘éœ€è¦æç¤º',
    'è¿™é“é¢˜å¥½éš¾',
    'æˆ‘æƒ³å†è¯•ä¸€æ¬¡',
    'è°¢è°¢è€å¸ˆ',
    'æˆ‘æ˜ç™½äº†',
    'èƒ½è¯¦ç»†è§£é‡Šä¸€ä¸‹å—',
    'è¿™ä¸ªæ–¹æ³•æˆ‘ä¸ä¼š',
    'è¿˜æœ‰å…¶ä»–åŠæ³•å—'
  ]
  
  const randomIndex = Math.floor(Math.random() * mockResults.length)
  const result = mockResults[randomIndex]
  const responseTime = Date.now() - startTime
  
  console.log('ğŸ­ æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«ç»“æœ:', result)
  
  res.json({
    success: true,
    data: {
      text: result,
      confidence: 0.88,
      responseTime,
      provider: 'mock'
    }
  })
}

/**
 * ğŸ­ è·å–æ¨¡æ‹Ÿè¯­éŸ³åˆæˆç»“æœ
 */
function getMockSynthesisResult(res, text, startTime) {
  console.log('ğŸ­ é™çº§ä½¿ç”¨æ¨¡æ‹Ÿè¯­éŸ³åˆæˆ')
  
  const responseTime = Date.now() - startTime
  
  return res.json({
    success: true,
    data: {
      audioUrl: null,
      audioData: `mock_${Buffer.from(text).toString('base64').substring(0, 20)}`,
      duration: Math.ceil(text.length / 5),
      text: text,
      responseTime,
      provider: 'mock',
      note: 'âš ï¸ è¿™æ˜¯æ¨¡æ‹Ÿæ•°æ®ï¼Œéœ€è¦å®‰è£…DashScope Python SDKä»¥ä½¿ç”¨çœŸå®è¯­éŸ³åˆæˆ'
    }
  })
}

/**
 * ğŸ“‹ å¤šå­¦ç§‘è¯­éŸ³æ’­æŠ¥é…ç½® - æŒ‰PRDè¦æ±‚å®ç°
 */
const SUBJECT_VOICE_CONFIG = {
  math: {
    voice: 'longxiaobai',
    speed: 1.0,
    textProcessor: 'preserveMathOperators',
    triggers: ['è®¡ç®—', 'ç­”æ¡ˆ', 'æ­£ç¡®', 'é”™è¯¯', 'å†æƒ³æƒ³', 'æç¤º']
  },
  chinese: {
    voice: 'longxiaochun', 
    speed: 0.9,
    textProcessor: 'preservePinyin',
    triggers: ['æ‹¼éŸ³', 'ç”Ÿå­—', 'è¯è¯­', 'å¥å­', 'é˜…è¯»', 'å†™ä½œ']
  },
  english: {
    voice: 'longxiaocheng',
    speed: 0.8,
    textProcessor: 'preserveEnglish',
    triggers: ['å•è¯', 'word', 'å‘éŸ³', 'è¯­æ³•', 'grammar', 'å¥å­']
  },
  science: {
    voice: 'longwan',
    speed: 1.0,
    textProcessor: 'preserveObservation',
    triggers: ['è§‚å¯Ÿ', 'å®éªŒ', 'ç°è±¡', 'åŸå› ', 'ç»“æœ', 'æ€è€ƒ']
  }
}

/**
 * ğŸ¯ åºåˆ—å·æ™ºèƒ½å¤„ç† - å°†"1. 2. 3."è½¬æ¢ä¸ºè‡ªç„¶è¯­éŸ³è¡¨è¾¾
 */
function processSequenceNumbers(text) {
  if (!text || typeof text !== 'string') return text
  
  // ğŸ”§ å¤„ç†åºåˆ—å·æ¨¡å¼ï¼šæ•°å­— + ç‚¹å· + ç©ºæ ¼/å†…å®¹
  const patterns = [
    // å¤„ç†"1. 2. 3."è¿™æ ·çš„åºåˆ—å· - å¢å¼ºç‰ˆæœ¬
    {
      regex: /(\s|^|ã€‚|ï¼|ï¼Ÿ)(\d+)\.\s*/g,
      replacer: (match, prefix, number) => {
        const num = parseInt(number)
        const chineseNumbers = ['', 'ç¬¬ä¸€', 'ç¬¬äºŒ', 'ç¬¬ä¸‰', 'ç¬¬å››', 'ç¬¬äº”', 'ç¬¬å…­', 'ç¬¬ä¸ƒ', 'ç¬¬å…«', 'ç¬¬ä¹', 'ç¬¬å']
        
        if (num <= 10) {
          return `${prefix}${chineseNumbers[num]}ï¼Œ`
        } else {
          return `${prefix}ç¬¬${num}ç‚¹ï¼Œ`
        }
      }
    },
    
    // å¤„ç†"ï¼ˆ1ï¼‰ï¼ˆ2ï¼‰ï¼ˆ3ï¼‰"è¿™æ ·çš„åºåˆ—å·
    {
      regex: /[ï¼ˆ(](\d+)[ï¼‰)]/g, 
      replacer: (match, number) => {
        const num = parseInt(number)
        const chineseNumbers = ['', 'ç¬¬ä¸€', 'ç¬¬äºŒ', 'ç¬¬ä¸‰', 'ç¬¬å››', 'ç¬¬äº”', 'ç¬¬å…­', 'ç¬¬ä¸ƒ', 'ç¬¬å…«', 'ç¬¬ä¹', 'ç¬¬å']
        
        if (num <= 10) {
          return `${chineseNumbers[num]}ï¼Œ`
        } else {
          return `ç¬¬${num}ç‚¹ï¼Œ`
        }
      }
    }
  ]
  
  let result = text
  patterns.forEach(pattern => {
    result = result.replace(pattern.regex, pattern.replacer)
  })
  
  console.log('ğŸ”¢ åºåˆ—å·å¤„ç†:', {
    original: text.substring(0, 100),
    processed: result.substring(0, 100),
    hasSequence: text !== result
  })
  
  return result
}

/**
 * ğŸ¯ å¤šå­¦ç§‘æ–‡æœ¬å¤„ç†å™¨ - æ ¹æ®å­¦ç§‘ç‰¹ç‚¹æ¸…ç†æ–‡æœ¬
 */
function processTextForSubject(text, subject = 'math') {
  if (!text || typeof text !== 'string') return ''
  
  let processed = text.trim()
  
  // ğŸ”¢ ç¬¬ä¸€æ­¥ï¼šå¤„ç†åºåˆ—å·ï¼ˆæ‰€æœ‰å­¦ç§‘éƒ½éœ€è¦ï¼‰
  processed = processSequenceNumbers(processed)
  
  // ğŸ”§ ç¬¬äºŒæ­¥ï¼šæ ¹æ®å­¦ç§‘è¿›è¡Œä¸“é—¨å¤„ç†
  switch (subject) {
    case 'math':
      // æ•°å­¦ï¼šä¿ç•™è¿ç®—ç¬¦ï¼Œç§»é™¤emoji
      processed = processed
        .replace(/[\u{1F600}-\u{1F6FF}\u{1F700}-\u{1F77F}\u{1F780}-\u{1F7FF}\u{1F800}-\u{1F8FF}\u{2600}-\u{26FF}\u{2700}-\u{27BF}]/gu, '')
        .replace(/[^\u4e00-\u9fa5a-zA-Z0-9\s+\-Ã—Ã·=ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰,.!?;:()\-]/g, '')
        .replace(/\s+/g, ' ').trim()
      break
      
    case 'chinese':
      // è¯­æ–‡ï¼šä¿ç•™æ‹¼éŸ³éŸ³è°ƒï¼Œç§»é™¤emoji
      processed = processed
        .replace(/[\u{1F600}-\u{1F6FF}\u{1F700}-\u{1F77F}\u{1F780}-\u{1F7FF}\u{1F800}-\u{1F8FF}\u{2600}-\u{26FF}\u{2700}-\u{27BF}]/gu, '')
        .replace(/[^\u4e00-\u9fa5a-zA-ZÄÃ¡ÇÃ Ä“Ã©Ä›Ã¨Ä«Ã­ÇÃ¬ÅÃ³Ç’Ã²Å«ÃºÇ”Ã¹Ç–Ç˜ÇšÇœ\sï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰]/g, '')
        .replace(/\s+/g, ' ').trim()
      break
      
    case 'english':
      // è‹±è¯­ï¼šä¿ç•™è‹±æ–‡ï¼Œç§»é™¤emojiå’Œä¸­æ–‡æ ‡ç‚¹
      processed = processed
        .replace(/[\u{1F600}-\u{1F6FF}\u{1F700}-\u{1F77F}\u{1F780}-\u{1F7FF}\u{1F800}-\u{1F8FF}\u{2600}-\u{26FF}\u{2700}-\u{27BF}]/gu, '')
        .replace(/[^\u4e00-\u9fa5a-zA-Z\s,.!?;:()\-]/g, '')
        .replace(/\s+/g, ' ').trim()
      break
      
    case 'science':
      // ç§‘å­¦ï¼šä¿ç•™è§‚å¯Ÿæè¿°ï¼Œç§»é™¤emoji
      processed = processed
        .replace(/[\u{1F600}-\u{1F6FF}\u{1F700}-\u{1F77F}\u{1F780}-\u{1F7FF}\u{1F800}-\u{1F8FF}\u{2600}-\u{26FF}\u{2700}-\u{27BF}]/gu, '')
        .replace(/[^\u4e00-\u9fa5a-zA-Z0-9\sï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰()Â°â„ƒ]/g, '')
        .replace(/\s+/g, ' ').trim()
      break
      
    default:
      // é»˜è®¤å¤„ç†ï¼šç§»é™¤emojiå’Œç‰¹æ®Šå­—ç¬¦
      processed = processed
        .replace(/[\u{1F600}-\u{1F6FF}\u{1F700}-\u{1F77F}\u{1F780}-\u{1F7FF}\u{1F800}-\u{1F8FF}\u{2600}-\u{26FF}\u{2700}-\u{27BF}]/gu, '')
        .replace(/[^\u4e00-\u9fa5a-zA-Z0-9\sï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰,.!?;:()\-]/g, '')
        .replace(/\s+/g, ' ').trim()
  }
  
  // ğŸ”§ ç¬¬ä¸‰æ­¥ï¼šæœ€ç»ˆæ¸…ç†
  processed = processed
    .replace(/ï¼Œ+/g, 'ï¼Œ')  // åˆå¹¶å¤šä¸ªé€—å·
    .replace(/ã€‚+/g, 'ã€‚')  // åˆå¹¶å¤šä¸ªå¥å·
    .replace(/\s+/g, ' ')   // åˆå¹¶å¤šä¸ªç©ºæ ¼
    .trim()
  
  return processed
}

/**
 * ğŸµ å¤šå­¦ç§‘è¯­éŸ³æ’­æŠ¥æ¥å£
 * POST /api/speech/broadcast
 * æ”¯æŒæ•°å­¦ã€è¯­æ–‡ã€è‹±è¯­ã€ç§‘å­¦å››ä¸ªå­¦ç§‘çš„è‡ªåŠ¨è¯­éŸ³æ’­æŠ¥
 */
router.post('/broadcast', async (req, res) => {
  const startTime = Date.now()
  
  try {
    console.log('ğŸµ æ”¶åˆ°å¤šå­¦ç§‘è¯­éŸ³æ’­æŠ¥è¯·æ±‚:', {
      text: req.body.text?.substring(0, 50) + (req.body.text?.length > 50 ? '...' : ''),
      subject: req.body.subject,
      priority: req.body.priority,
      userId: req.body.userId
    })

    const { 
      text, 
      subject = 'math', 
      priority = 'normal', 
      autoPlay = true, 
      userId 
    } = req.body

    // å‚æ•°éªŒè¯
    if (!text || text.trim().length === 0) {
      return res.status(400).json({
        success: false,
        error: 'æ’­æŠ¥æ–‡æœ¬ä¸èƒ½ä¸ºç©º'
      })
    }

    if (text.length > 500) {
      return res.status(400).json({
        success: false,
        error: 'æ’­æŠ¥æ–‡æœ¬é•¿åº¦ä¸èƒ½è¶…è¿‡500å­—ç¬¦'
      })
    }

    // ğŸ¯ å¤šå­¦ç§‘è¯­éŸ³é…ç½®
    const subjectConfigs = {
      math: {
        voice: 'longxiaobai',
        speed: 1.0,
        description: 'æ•°å­¦å°è€å¸ˆ - é€»è¾‘æ¸…æ™°ï¼Œæ¸©æš–é¼“åŠ±'
      },
      chinese: {
        voice: 'longxiaochun',
        speed: 0.9,
        description: 'è¯­æ–‡è€å¸ˆ - å£°éŸ³ç”œç¾ï¼Œå¯Œæœ‰æ„Ÿæƒ…'
      },
      english: {
        voice: 'longxiaocheng',
        speed: 0.8,
        description: 'è‹±è¯­è€å¸ˆ - å‘éŸ³æ ‡å‡†ï¼Œæ´»æ³¼ç”ŸåŠ¨'
      },
      science: {
        voice: 'longwan',
        speed: 1.0,
        description: 'ç§‘å­¦è€å¸ˆ - çŸ¥è¯†æ¸Šåšï¼Œå¼•å¯¼æ¢ç´¢'
      }
    }

    // è·å–å­¦ç§‘é…ç½®
    const config = subjectConfigs[subject] || subjectConfigs.math
    console.log('ğŸ¯ ä½¿ç”¨å­¦ç§‘é…ç½®:', {
      subject: subject,
      voice: config.voice,
      speed: config.speed,
      description: config.description
    })

    // ğŸ”§ æ–‡æœ¬é¢„å¤„ç† - é’ˆå¯¹å­¦ç§‘ç‰¹ç‚¹ä¼˜åŒ–
    let processedText = text.trim()
    
    // åºåˆ—å·å¤„ç†ï¼ˆå¦‚"1. 2. 3."ï¼‰
    processedText = processSequenceNumbers(processedText)
    
    // å­¦ç§‘ç‰¹å®šæ–‡æœ¬å¤„ç†
    processedText = processTextForSubject(processedText, subject)

    console.log('ğŸ“ æ–‡æœ¬å¤„ç†å®Œæˆ:', {
      originalLength: text.length,
      processedLength: processedText.length,
      originalText: text.substring(0, 30),
      processedText: processedText.substring(0, 30)
    })

    // ğŸµ æ‰§è¡Œè¯­éŸ³åˆæˆ
    const synthResult = await performSpeechSynthesis(
      processedText, 
      config.voice, 
      config.speed, 
      1.0 // pitch
    )
    
    const processingTime = Date.now() - startTime
    
    // æ„é€ è¿”å›æ•°æ®
    const responseData = {
      text: text,
      processedText: processedText,
      subject: subject,
      voice: config.voice,
      speed: config.speed,
      priority: priority,
      duration: synthResult.duration || Math.ceil(processedText.length / 3),
      audioUrl: synthResult.audioUrl || `data:audio/mp3;base64,${synthResult.audioData}`,
      audioData: synthResult.audioData,
      audioSize: synthResult.audioSize || 0,
      provider: synthResult.provider || 'alibaba-cloud',
      responseTime: processingTime,
      userId: userId,
      timestamp: new Date().toISOString(),
      qualityCheck: synthResult.qualityCheck || {
        size: synthResult.audioSize || 0,
        isValidSize: (synthResult.audioSize || 0) >= 1000,
        estimatedDuration: Math.ceil(processedText.length / 3),
        quality: synthResult.provider === 'mock' ? 'mock' : 'real',
        isValidMP3: synthResult.provider !== 'mock'
      }
    }

    console.log(`âœ… å¤šå­¦ç§‘è¯­éŸ³æ’­æŠ¥æˆåŠŸ (${processingTime}ms):`, {
      subject: subject,
      voice: config.voice,
      textLength: processedText.length,
      audioSize: synthResult.audioSize,
      duration: responseData.duration + 's',
      provider: synthResult.provider
    })
    
    res.json({
      success: true,
      data: responseData
    })

  } catch (error) {
    const processingTime = Date.now() - startTime
    console.error('âŒ å¤šå­¦ç§‘è¯­éŸ³æ’­æŠ¥å¤±è´¥:', error)
    
    // ğŸ”§ ä¼˜é›…é™çº§ï¼šå³ä½¿è¯­éŸ³åˆæˆå¤±è´¥ï¼Œä¹Ÿä¸å½±å“ä¸»è¦åŠŸèƒ½
    res.json({
      success: false,
      error: process.env.NODE_ENV === 'development' ? error.message : 'è¯­éŸ³æ’­æŠ¥æœåŠ¡æš‚æ—¶ä¸å¯ç”¨',
      fallback: true,
      responseTime: processingTime,
      subject: req.body.subject || 'math',
      text: req.body.text
    })
  }
})

/**
 * ğŸ¯ è·å–å­¦ç§‘è¯­éŸ³é…ç½®æ¥å£ - GET /api/speech/subject-config
 */
router.get('/subject-config', (req, res) => {
  const subject = req.query.subject
  
  if (subject && SUBJECT_VOICE_CONFIG[subject]) {
    return res.json({
      success: true,
      data: {
        subject: subject,
        config: SUBJECT_VOICE_CONFIG[subject],
        supportedSubjects: Object.keys(SUBJECT_VOICE_CONFIG)
      }
    })
  }
  
  // è¿”å›æ‰€æœ‰å­¦ç§‘é…ç½®
  return res.json({
    success: true,
    data: {
      allConfigs: SUBJECT_VOICE_CONFIG,
      supportedSubjects: Object.keys(SUBJECT_VOICE_CONFIG),
      defaultSubject: 'math'
    }
  })
})

module.exports = router 